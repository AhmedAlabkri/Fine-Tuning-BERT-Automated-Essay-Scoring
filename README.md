# Fine-Tuning-BERT-Automated-Essay-Scoring
The project investigates the use of a pre-trained NLP model (BERT) for automating essay scoring using a regression technique. We compared two approaches: 1) Fine-tuning BERT on IELTS essay responses with the prompt given to the students, and 2) Doing the same as approach 1 but with added custom features extracted from the dataset.

# Overview-Goals
The goal is to compare AI-driven scoring with human scoring to assess the accuracy and efficiency of AI in educational assessments. We also aim to test the capabilities and strengths of the BERT model. For this reason, in model two, we added additional features to see if there would be any improvement.

# Problem statment/Why?
NLP algorithms are being used to score essays, but itâ€™s unclear how well they compare to human scorers. In general, human scoring of essays is slow and can be inconsistent, for instance, the same test scorer might give the same piece of writing different score depanding in so many factors. In contrast, AI can score essays quickly and consistently but struggles with understanding nuanced language. This project compares AI-driven scoring using the BERT model with human scoring to see if AI can be just as accurate and efficient.
